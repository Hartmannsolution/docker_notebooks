{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas: Series, Data Frames and Time Series\n",
    "\n",
    "Pandas is -similar to NumPy- another library offering high-level data structures, which enable fast data analyzis. For us, the most important are probably the types `Series` and `DataFrame`, both of which are introduced in the following.  \n",
    "\n",
    "This tutorial is based on the [intro to Pandas:](http://pandas.pydata.org/pandas-docs/stable/10min.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TOC\n",
    "\n",
    "- Pandas\n",
    "  - Loading and reading data\n",
    "  - Series\n",
    "    - 1 dimensional data structure\n",
    "  - DataFrame\n",
    "    - 2 dimensional data structure\n",
    "    - `pandas.DataFrame( data, index, columns, dtype, copy)`\n",
    "    - columns can be of different types\n",
    "    - data can be lists, dicts, maps, ndarrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Initialising`pandas`,`numpy` and `matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline \n",
    "# %pylab is a magic function in ipython, and triggers the import of various modules within Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above magic function equals\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "```\n",
    "Magic function: `%matplotlib inline` is to show plots directly below code as part of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## Pandas vs Numpy\n",
    "1. In pandas we have 1D Series and 2D DataFrame in numpy we have multi dimensional ndArrays\n",
    "2. In DataFrame we have column names (like in sql) in ndArrays we have data slicing based in indices\n",
    "3. In DataFrame we can have multiple datatypes in different columns\n",
    "  \n",
    "![](images/pandas_vs_numpy.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we need pandas\n",
    "Source: Python for data analysis\n",
    "\n",
    "###  data preparation: \n",
    "- loading, \n",
    "- visualizing (in dataframes)\n",
    "- cleaning, \n",
    "- transforming, and \n",
    "- rearranging\n",
    "\n",
    "pandas, along with the built-in Python language features, provides us with a high-level, flexible, and fast set of tools, so we can manipulate data into the form we need it in.\n",
    "\n",
    "### Common tasks:\n",
    "- Handling missing data\n",
    "  - Filtering out missing data\n",
    "  - Filling in missing data\n",
    "- Data transformation\n",
    "  - Removing dublicates\n",
    "  - Transforming Data Using a Function or Mapping\n",
    "  - Replacing Values\n",
    "  - Renaming Axis Indexes\n",
    "  - Discretization and Binning\n",
    "  - Detecting and Filtering Outliers\n",
    "  - Permutation (randomly reordering) and Random Sampling\n",
    "  - create indicator (or dummy) variables\n",
    "- String manipulation\n",
    "  - Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data\n",
    "|Method|Description|\n",
    "|--|--|\n",
    "| dropna | Filter axis labels based on whether values for each label have missing data, with varying thresholds for how much missing data to tolerate. |\n",
    "| fillna | Fill in missing data with some value or using an interpolation method such as 'ffill' or 'bfill'. |\n",
    "| isnull | Return boolean values indicating which values are missing/NA. |\n",
    "| notnull | Negation of isnull. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String manipulation \n",
    "\n",
    "|String method|Description|\n",
    "|--|--|\n",
    "|count | Return the number of non-overlapping occurrences of substring in the string. |\n",
    "|endswith | Returns True if string ends with suffix. |\n",
    "|startswith | Returns True if string starts with prefix. |\n",
    "|join | Use string as delimiter for concatenating a sequence of other strings. |\n",
    "|index | Return position of first character in substring if found in the string; raises ValueError if not found. |\n",
    "|find | Return position of first character of first occurrence of substring in the string; like index, but returns –1 |\n",
    "|rfind | if not found. |\n",
    "|replace | Return position of first character of last occurrence of substring in the string; returns –1 if not found. |\n",
    "|strip, | Replace occurrences of string with another string. |\n",
    "|rstrip, | Trim whitespace, including newlines; equivalent to x.strip() (and rstrip, lstrip, respectively) |\n",
    "|lstrip | for each element. |\n",
    "|split | Break string into list of substrings using passed delimiter. |\n",
    "|lower | Convert alphabet characters to lowercase. |\n",
    "|upper | Convert alphabet characters to uppercase. |\n",
    "|casefold | Convert characters to lowercase, and convert any region-specific variable character combinations to a |\n",
    "|ljust, | common comparable form. |\n",
    "|rjust | Left justify or right justify, respectively; pad opposite side of string with spaces (or some other fill character) to return a string with a minimum width. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import as pd\n",
    "Makes code easier to read if we follow the convention of other programmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Learning a new framework\n",
    "\n",
    "1. Study the API\n",
    "  * https://pandas.pydata.org/pandas-docs/stable/reference/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Getting data with Pandas\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/io.html\n",
    "\n",
    "```python\n",
    "pd.read_csv(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head data/befkbhalderstatkode.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/befkbhalderstatkode.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### columns in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* What is the dimensionality of the dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Getting a column of data by name:\n",
    "What data type is the column?\n",
    "```python\n",
    "df['ALDER']\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('Data type of a column',type(df['ALDER']),'\\n')\n",
    "print('All ages in the dataset',set(df['ALDER']))\n",
    "df['ALDER']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing a column of data by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(type(df.iloc[:,0]))\n",
    "df.iloc[:,0] # all rows of first column: same as df['AAR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing a row of data by index\n",
    "Notice how we get a Series object with **labels** being the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_row = df.iloc[0,:] # or just df.iloc[0]\n",
    "print(type(first_row))\n",
    "first_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row['AAR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Get the second element of the third column using the `iloc` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# iloc (integer location method)\n",
    "col = 0\n",
    "row = 1\n",
    "df.iloc[row][col] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with loc\n",
    "print(df.index)\n",
    "print(first_row.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe 3x2\n",
    "test = pd.DataFrame([[1, 2], [4, 5], [7, 8]],index=['cobra', 'viper', 'sidewinder'],columns=['max_speed', 'shield'])\n",
    "print(test)\n",
    "print('\\n')\n",
    "print(test.index)\n",
    "print('sidewinders max speed is {}'.format(test.loc['sidewinder','max_speed']))\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 Class exercise slicing dataframe\n",
    "Use this data:\n",
    "```python\n",
    "data = np.array([['','Col1','Col2','col3'],\n",
    "                ['Row1',1,2,3],\n",
    "                ['Row2',4,5,6],\n",
    "                ['Row3',7,8,9]])\n",
    "```\n",
    "1. Create a DataFrame (wrap the data above in a pandas DataFrame in a way that printing the dataframe and its index and column attributes gives this result)  \n",
    "`pd.DataFrame(data=data[1:4,1:4], columns=data[0,1:4], index=data[1:4,0])`  \n",
    "\n",
    "``` \n",
    "     Col1 Col2 col3  \n",
    "Row1    1    2    3\n",
    "Row2    4    5    6\n",
    "Row3    7    8    9\n",
    "\n",
    "Index(['Row1', 'Row2', 'Row3'], dtype='object')\n",
    "Index(['Col1', 'Col2', 'col3'], dtype='object')\n",
    "```\n",
    "\n",
    "2. Make slices of data:\n",
    "   1. second column using column name\n",
    "   2. third column using column index (.iloc[])\n",
    "   3. slice element at third row of second column (use .iloc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([['','Col1','Col2','col3'],\n",
    "                ['Row1',1,2,3],\n",
    "                ['Row2',4,5,6],\n",
    "                ['Row3',7,8,9]])\n",
    "\n",
    "pd.DataFrame(data)\n",
    "pd.DataFrame(data=data[1:4,1:4], columns=data[0,1:4], index=data[1:4,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `Pandas Series` (like dictionary with added functionality ...)\n",
    "\n",
    "A `Series` is a labeled array (one-dimensional ndarrays with axis-labels) capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index. The data structure is similar to the python dictionary, but it differs in that pandas series has a lot of methods for complex data manipulation.\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/dsintro.html#series\n",
    "\n",
    "You can create a Series by passing a list of values, letting Pandas create a default integer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pandas Series with multiple data types\n",
    "s = pd.Series([1, 3, 5, np.nan, 'seks', 8])\n",
    "print(s,'\\n---------------------')\n",
    "s = pd.Series(['seks','fem','fire'],[6,5,4]) # in pd.Series we can provide any keys we like to the data\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Real world use case\n",
    "### World bank data: CO2 emissions\n",
    "For the following example introducing `Series` we will collect some open data from the World Bank, see http://data.worldbank.org/?locations=DK-UY. This dataset includes a plethora of interesting data. However, for this example we will focus on the *CO2 emissions*.\n",
    "Hint: Find the csv file in the data folder\n",
    "\n",
    "First, we have to download the data. We do this by writing the response to a request to the World Bank API into a file. As denoted in the response header, we receive a ZIP file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# url = 'http://api.worldbank.org/v2/en/country/DNK;URY' \n",
    "# response = requests.get(url, params={'downloadformat': 'csv'})\n",
    "url = 'http://api.worldbank.org/v2/en/indicator/EN.ATM.CO2E.KT?downloadformat=csv'\n",
    "response = requests.get(url)\n",
    "\n",
    "print(response.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# get the filename\n",
    "fname = response.headers['Content-Disposition'].split('=')[1]\n",
    "fname = 'data/'+fname\n",
    "# write content to file (zip file writing bytes)\n",
    "if response.ok:  # status_code == 200:\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(response.content)   \n",
    "print('-----------------')\n",
    "print('Downloaded {}'.format(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls data/API*.zip\n",
    "# ls -ltrh data | tail\n",
    "#man ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can resort to the standard libraries `zipfile` module to uncompress the downloaded file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "# extract content of zip file in current folder\n",
    "zipfile.ZipFile(fname, 'r').extractall('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head data/API_EN.ATM.CO2E.KT_DS2_en_csv_v2_1345584.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/API_EN.ATM.CO2E.KT_DS2_en_csv_v2_1345584.csv', skiprows=4)\n",
    "columns_names = data.columns\n",
    "print('column names:\\n',list(columns_names),'\\n\\n')\n",
    "countries = data['Country Name']\n",
    "print('{} countries are in the dataset.'.format(len(countries)),'\\n')\n",
    "print('countries are of data type: ',type(countries),'\\n')\n",
    "print(list(countries))\n",
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new pandas Series with countries as labels and a random number as values\n",
    "import random\n",
    "# random.sample(population, k): returns k random and unique members of the population.\n",
    "random_val_pr_country = pd.Series(random.sample(range(1,len(countries)+1),len(countries)),index=countries)\n",
    "random_val_pr_country.sort_values()\n",
    "#random_val_pr_country.sort_index(level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instansiate Series from dict\n",
    "new_series = pd.Series(dict({'a':3,'b':6,'c':9}))\n",
    "new_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.read_csv('./data/country_codes.csv', sep='\\t', header=None)[2]\n",
    "codes[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Exercise Pandas Data Series\n",
    "The CO2 Emission data set above is not updated since 2014\n",
    "1. Create a Pandas Series with emission data from 2014 for each country or region\n",
    "2. Find the 10 Countries/Regions with the highest emissions in 2014 and show emission numbers (reverse sorted)\n",
    "3. Remove if you can those rows that are not countries (regions and aggregated groups) (hint:  [ISO 3166, Alpha-3 country codes](https://www.iban.com/country-codes), a csv file can be found here: `/data/country_codes.csv`)\n",
    "    - Find the 10 countries with highest emissions in 2014\n",
    "4. Plot the emissions of China and USA over time respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# `DataFrame`\n",
    "\n",
    "A `DataFrame` is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or **a dict of Series objects**.\n",
    "\n",
    "In the following we **concatenate** two `Series`to form a `DataFrame`.\n",
    "\n",
    "We will use pandas concat() method [get a good explanation here](https://www.tutorialspoint.com/python_pandas/python_pandas_concatenation.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Country Name','2014']]\n",
    "newData = data[['Country Name','2014']].sort_values('2014', ascending=False)\n",
    "newData.set_index('Country Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 SERIES\n",
    "# CO2 data\n",
    "years = data.columns[4:]\n",
    "#data.loc[data['Country Name'=='Denmark']]\n",
    "data.columns\n",
    "list(data['Country Name'])\n",
    "ts_dk = data.loc[data['Country Name']=='Denmark'].iloc[0][4:-6]\n",
    "ts_ury = data.loc[data['Country Name']=='Uruguay'].iloc[0][4:-6]\n",
    "ts_ury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCAT\n",
    "ts = pd.concat([ts_dk, ts_ury], axis=1, keys=['DNK', 'URY']) # axis=0 is default (concats like sql UNION) axis=1 concats the data along the x axis\n",
    "print(ts[:4])\n",
    "ts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "More information on `DataFrame`s can be found here:\n",
    "http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe\n",
    "\n",
    "Similar to, we can create `DataFrame`s by giving the data for the values and indexes explicitely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dates = pd.date_range('20200602', periods=6) # create 6 dates from september 2nd, 2020.\n",
    "df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD')) # use np.random.randn to generate a dataframe of 6 by 4 random numbers\n",
    "print(dates)\n",
    "print(df)\n",
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 03 Exercise pandas dataframe\n",
    "1. Using the dataframe in the above cell find:\n",
    "    1. Mean, Min, Max values for all 4 columns\n",
    "    2. The 2 dates with the largest and smallest sum (by column)\n",
    "    3. All dates where both A's and B's are positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few useful pandas methods\n",
    "1. `df.set_index('Col name here')` set index of a data frame to be one of the columns (must be unique values)\n",
    "2. `df.sort_values(ascending=False)`\n",
    "3. `pd.read_csv('../../../data/country_codes.csv', sep='\\t', header=None)` \n",
    "4. `df['col'].str.strip()` use ds.str.some_method to do string operations on all values in dataframe column (data series)\n",
    "5. `data[data['Column Name'].isin(some_list)]` Filters all rows to only those where the value in specified column exists in a specified list\n",
    "6. `filter = as_and_bs[as_and_bs > 0]` Create a filter where all non-validate values is replaced with NaN\n",
    "7. `filter_na = filter.notna()` create a boolean mask to remove all NaN values\n",
    "8. `filter_na.any(axis=1)` any() includes all rows where a single True is present\n",
    "9. `filter_na.all(axis=1)` all() includes only those rows where all cells are True\n",
    "10. `ds.replace(val1,val2)` replaces all instances of val1 with val2\n",
    "11. `data[['col1','col2']].apply(pd.to_numeric)` convert all values of collumn 1 and 2 from string to numeric\n",
    "12. `df['col 3'] = df['col1']/df['col2']` creates a new column in the data frame with the result of dividing each value in column 1 with the equivilent value in column 2\n",
    "13. `df.groupby(['col1','col3']).sum().reset_index()`\n",
    "14. `df[df['col name']==some_value]` filter rows based on value\n",
    "15. merge\n",
    "16. When data is on different rows for same entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base data frames\n",
    "import pandas as pd\n",
    "data_people = {'Name':['Henning', 'Hassan', 'Helle', 'Harissa'],'Age':[20, 21, 19, 18], 'Phone':[3,2,4,1]} \n",
    "data_phones = {'Id':[1,2,3,4],'Number':['+4598877665','+4523344556','+4543543456','+4539105843'],'Description':['Home','Work','Home','Mobile']}\n",
    "df_people = pd.DataFrame(data_people)\n",
    "df_phones = pd.DataFrame(data_phones)\n",
    "df_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1 set_index\n",
    "df_phones_new = df_phones.set_index('Number')\n",
    "df_phones_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after set_index, now we can find by number\n",
    "df_phones_new.loc['+4523344556']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index\n",
    "df_phones_old = df_phones_new.reset_index()\n",
    "df_phones_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. sort\n",
    "df_people_sorted = df_people.sort_values('Age',ascending=False)\n",
    "df_people_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4. use DataSeries .str attribute to apply string methods to a column in a dataframe\n",
    "df_people['Name'] = df_people['Name'].str.\n",
    "\n",
    "df_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. isin() filters all rows based on whether value is in list\n",
    "df_phones[df_phones['Number'].isin(['+4598877665','+4543543456'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phones\n",
    "#df_phones[df_phones['Number'].isin(['+4598877665','+4543543456'])]\n",
    "df_phones_new[df_phones_new.index.isin(['+4598877665','+4543543456'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 6. filter\n",
    "df_people_filtered = df_people[df_people['Age'] > 19]\n",
    "df_people_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 any()\n",
    "df = pd.DataFrame({\"A\":[2,0,1], \"B\":[1,0,0], \"C\":[0,0,0]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.any() # axis defaults to 0 = rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.any(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. apply()\n",
    "age_phone = df_merged[['Age','Phone']].apply(pd.to_numeric)\n",
    "age_phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. apply with lambda (axis=1 means rowwise, axis=0 is columnwise) a row is a dataseries and it has a sum method\n",
    "\n",
    "df_merged['Summed'] = age_phone.apply(lambda row:row.sum(), axis=1)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. new column\n",
    "df_merged['new column'] = df_merged['Age']/df_merged['Phone']*100\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. merged\n",
    "df_merged = pd.merge(df_people, df_phones, left_on='Phone', right_on='Id')\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. One way to use values on seperate rows\n",
    "# Find average achivements pr. year\n",
    "data_people = {'Name':['Henning', 'Henning', 'Harissa', 'Harissa'],'Age':[20, None, 19, None], 'Achievements':[None,40,None,35]} \n",
    "df = pd.DataFrame(data_people)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = df[df['Age'].notnull()]\n",
    "achieve = df[df['Achievements'].notnull()]\n",
    "print(age)\n",
    "average = age['Age']/achieve['Achievements'].tolist() # tolist() is used here because the rows of age and achieve are of different index (alternative: use .reset_index())\n",
    "result = age.copy()\n",
    "result['Result'] = average\n",
    "result[['Name','Result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 12. groupby\n",
    "people_account = {'Name':['Henning', 'Hassan', 'Helle', 'Harissa'],'Age':[20, 20, 19, 19], 'Account':[100,200,300,400]} \n",
    "df = pd.DataFrame(people_account)\n",
    "print(df)\n",
    "# group by age and sum up the Account column (reset index to get a new 0 indexed dataframe)\n",
    "df.groupby('Age')['Account'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boolean filtering example\n",
    "mask = df_merged['Description'] == 'Home'\n",
    "df_merged[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe to Series and back\n",
    "Using stack() and unstack() to change a dataframe into a Series and back. If Dataframe has 2 columns, the Series will get 2 (hieracical) indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = df.stack()\n",
    "print(type(series))\n",
    "print(series.index)\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Working with real data\n",
    "Since we do not want to work on random example data. We will have a look on the **military expenditures** of some countries in the world. We will use this data to exemplify usage of Pandas' `DataFrame` methods.\n",
    "\n",
    "Again, we will receive the data from the World Bank.\n",
    "http://data.worldbank.org/indicator/MS.MIL.XPND.CN?locations=DK-CN-US-RU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://api.worldbank.org/v2/en/indicator/MS.MIL.XPND.CN'\n",
    "\n",
    "response = requests.get(url, params={'downloadformat': 'csv'})\n",
    "fname = response.headers['Content-Disposition'].split('=')[1]\n",
    "print(response.headers)\n",
    "\n",
    "if response.ok:  # status_code == 200:\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(response.content)   \n",
    "\n",
    "print('Downloaded',fname)\n",
    "#print('Downloaded {}'.format(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "zipfile.ZipFile(fname, 'r').extractall('.')\n",
    "os.remove(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -ltrh | tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "head ./data/Metadata_Indicator_API_MS.MIL.XPND.CN_DS2_en_csv_v2_898165.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, we use Pandas' `read_csv` function to read the downloaded CSV file directly. Note that we have to skip the first four rows as they do not contain data we are interested in, see keyword argument `skiprows=4`.\n",
    "\n",
    "Reading the CSV file like this returns a `DataFrame` directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "expenditure_csv = 'data/API_MS.MIL.XPND.CN_DS2_en_csv_v2_898165.csv'\n",
    "\n",
    "expenditures = pd.read_csv(expenditure_csv, skiprows=4)\n",
    "expenditures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Viewing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditures.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditures.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditures.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditures.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Selection of Data in a `DataFrame`\n",
    "\n",
    "### Selection by Column Name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(expenditures['Country Name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(expenditures['Country Code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Selection by Indexes\n",
    "\n",
    "In the following we index the third row directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get row 3\n",
    "albania = expenditures.iloc[3]\n",
    "print(albania)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using .loc to extract by label (row or column)\n",
    "expenditures.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditures.iloc[3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# extract sub set of [rows,columns]\n",
    "expenditures.iloc[3:5, 4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Boolean Indexing\n",
    "\n",
    "Similar to NumPy, you can use boolean arrays for indexing. That is, you can use boolean expressions directly for indexing.\n",
    "\n",
    "In the following we assign `expenditures` to `df`as the latter is shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = expenditures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Using the `isin()` method for filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Country Name'].isin(['United States', 'China', 'Denmark', 'Russian Federation'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here, we create a `DataFrame` of all country codes for the four countries, which we want to study further in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices for the 4 countries in question:\n",
    "c_codes = df[df['Country Name'].isin(['United States', 'China', \n",
    "                                        'Denmark', 'Russian Federation'])]['Country Code']\n",
    "c_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We cannot plot the time series of military expenditures directly in a meaningful way as we would like to have the years on the y-axis but in the selection of our `DataFrame`, the year numbers are column names. Consequently, we have to transpose our `DataFrame`, see `T` function.\n",
    "\n",
    "Note, that the expenditures are given in `LUC` in the World Bank data set. That is, in currency of the corresponding country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get only the 4 countries from df and only cols: 31-end (only 1987 and up)\n",
    "#print(df.iloc[c_code_df.index,31:-1])\n",
    "ts_df = df.iloc[c_codes.index, 31:-1]\n",
    "print(ts_df)\n",
    "ts_df = ts_df.T\n",
    "print(ts_df)\n",
    "ts_df = ts_df.rename(columns=dict(c_codes))\n",
    "print(ts_df)\n",
    "ts_df\n",
    "ts_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Since this plot may be a bit misleading, we will 'normalize' all expeditures to Euro, so that they are better comparible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "# http://www.ecb.europa.eu/stats/policy_and_exchange_rates/euro_reference_exchange_rates/html/index.en.html#dev\n",
    "response = requests.get('http://www.ecb.europa.eu/stats/eurofxref/eurofxref-daily.xml')\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# Will be covered in week 7 on webscraping\n",
    "\n",
    "xml = BeautifulSoup(response.text, 'html.parser')\n",
    "rate_list = xml.cube.cube.findAll(\"cube\") # [0]['rate']\n",
    "print(xml.cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "currency = ['USD', 'DKK', 'RUB', 'CNY']\n",
    "rate_dict = dict.fromkeys(currency) # create a new dict with given keys\n",
    "#print(rate_dict)\n",
    "for element in rate_list:\n",
    "    if element['currency'] in currency:\n",
    "        rate_dict[element['currency']] = float(element['rate'])\n",
    "        print(element['rate'])\n",
    "rate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# get all weapons expenditure in euros\n",
    "ts_df['DNK'] = ts_df['DNK'] / rate_dict['DKK']\n",
    "ts_df['USA'] = ts_df['USA'] / rate_dict['USD']\n",
    "ts_df['CHN'] = ts_df['CHN'] / rate_dict['CNY']\n",
    "ts_df['RUS'] = ts_df['RUS'] / rate_dict['RUB']\n",
    "ts_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**OBS!!!** Be careful, the graph above is still not really well suited for comparison as currency exchange rates are not fix. However, the code above normalizes just relying on the most current exchange rate from the European Central Bank. See the exercise block in the bottom for how to fix that isuue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting dataframes\n",
    "\n",
    "In case you have to sort the data in your `DataFrames` see the methods `sort_index` and `sort_values`.\n",
    "\n",
    "\n",
    "```python\n",
    "df.sort_index(axis=1, ascending=True)\n",
    "df.sort_values(by='Country Code')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 Class Exercise\n",
    "#### Find military expenditure pr. capita.\n",
    "\n",
    "Go here and get data as csv: [worldbank military expanditure](https://databank.worldbank.org/reports.aspx?source=2&series=MS.MIL.XPND.CD&country=#). Download it manually, unzip the csv and clean up empty rows.  \n",
    "1. Use .replace() method on the dataframe to remove all data containing '..'\n",
    "2. Set index of the dataframe to be 'Country Name'\n",
    "3. Slice the 2019 column data to get a data series.\n",
    "4. Make data numeric (pd.to_numeric(data_series))\n",
    "\n",
    "1. For 2019 find the 10 countries with the highest military expenditure in USD\n",
    "2. For 2019 find the 10 countries with the highest military expenditure per capita. Find the population data here: [worldbank](https://databank.worldbank.org/source/world-development-indicators/preview/on#)(use series='Population,Total' and time='2019' and Country= countries (217)) **or** use [copy paste with this date into excel](https://www.worldometers.info/world-population/population-by-country/)\n",
    "  - (Hint: use pd.merge() to merge the mil_exp dataframe with the population dataframe on 2 columns (country_code)\n",
    "3. For 2019 find the 3 countries with the highest per capita military expenditure in the middle east\n",
    "  - [countries list with iso code](middleeast_countries.csv) or use:   \n",
    "  `list_of_middle_eastern = ['YEM','ARE','TUR','SYR','SAU','QAT','PSE','OMN','LBN','KWT','JOR','ISR','IRQ','IRN','EGY','CYP','BHR']`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## Self study exercise\n",
    "\n",
    "Complete the comparison of military expenditures by converting all currencies to USD. Since we have yearly expenditures, use for example the yearly median for normalization. Likely, you will find an API to collect historical echange rates at Yahoo Finance.\n",
    "\n",
    "[https://finance.yahoo.com/quote/USDRUB%3DX](https://finance.yahoo.com/quote/USDRUB%3DX)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv('https://api.statbank.dk/v1/data/FOLK1A/CSV?delimiter=Semicolon&OMR%C3%85DE=*&K%C3%98N=*&ALDER=IALT&CIVILSTAND=TOT',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting bar chart\n",
    "```python\n",
    "\n",
    "df = pd.DataFrame(np.random.rand(6, 4),\n",
    "     index=['one', 'two', 'three', 'four', 'five', 'six'],\n",
    "     columns=pd.Index(['A', 'B', 'C', 'D'], name='Genus'))\n",
    "df.plot.bar()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = pd.DataFrame(np.random.rand(6, 4),\n",
    "     index=['one', 'two', 'three', 'four', 'five', 'six'],\n",
    "     columns=pd.Index(['A', 'B', 'C', 'D'], name='Genus'))\n",
    "df.plot.bar()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.barh(stacked=True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df = pd.DataFrame({'key1' : ['a', 'a', 'b', 'b', 'a'],\n",
    "     'key2' : ['one', 'two', 'one', 'two', 'one'],\n",
    "     'data1' : np.random.randn(5),\n",
    "     'data2' : np.random.randn(5)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df['data1'].groupby(df['key1'])\n",
    "grouped2 = df['data1'].groupby([df['key1'], df['key2']])\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean:\\n',grouped.mean())\n",
    "print('max:\\n',grouped.max())\n",
    "print('sum:\\n',grouped.sum())\n",
    "print()\n",
    "print('grouped2:\\n ', grouped2.sum()) # creates a hierachical indexed series\n",
    "print('indices:\\n',grouped2.sum().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping with dict and series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = pd.DataFrame(np.random.randn(5, 5),\n",
    "columns=['a', 'b', 'c', 'd', 'e'],\n",
    "index=['Joe', 'Steve', 'Wes', 'Jim', 'Travis'])\n",
    "people.iloc[2:3, [1, 2]] = np.nan # Add a few NA values\n",
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# its ok to have extra (unused) keys in the dict like 'f' below:\n",
    "mapping = {'a': 'red', 'b': 'red', 'c': 'blue', 'd': 'blue', 'e': 'red', 'f' : 'orange'}\n",
    "by_column = people.groupby(mapping, axis=1)\n",
    "by_column.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping with functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by the result of the len() function\n",
    "people.groupby(len).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixing functions with arrays, dicts, or Series is not a problem as everything gets converted to arrays internally\n",
    "key_list = ['one', 'one', 'one', 'two', 'two']\n",
    "people.groupby([len, key_list]).min()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
