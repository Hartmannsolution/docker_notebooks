{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 keras models\n",
    "### Following the mnist tutorial linked from previous notebook\n",
    "Build and train a model to predict handwritten digits from mnist dataset.  \n",
    "The typical Keras workflow looks just like this:\n",
    "1. Define your training data: input tensors and target tensors.\n",
    "2. Define a network of layers (or model ) that maps your inputs to your targets.\n",
    "3. Configure the learning process by choosing a loss function, an optimizer, and some metrics to monitor.\n",
    "4. Iterate on your training data by calling the fit() method of your model.\n",
    "\n",
    "Great video [here](https://www.youtube.com/watch?v=5qCDzaOUCWA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target on entity no. 35: 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Some rows from input on entity no 35: [[  0   0   0   0   0   0   0   0   0   0   0   0   0 141 226 170  57   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  86 255 198  29   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 198 255 141  86  57   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 170 255 198 114 226 170  29\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  57 198 255 114  29   0 141 255  29\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# x_train[35]\n",
    "print(f'Target on entity no. 35: {y_train[35]}')\n",
    "print('\\n\\n\\n')\n",
    "print(f'Some rows from input on entity no 35: {x_train[35][10:15]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_index = 35\n",
    "print(y_train[image_index])\n",
    "plt.imshow(x_train[image_index], cmap='Greys')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(y_train[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "#28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.11372549, 0.5529412 ,\n",
       "       0.7764706 , 1.        , 0.7764706 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.3372549 , 0.5529412 ,\n",
       "       0.7764706 , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.6666667 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.11372549, 0.5529412 ,\n",
       "       0.8862745 , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.7764706 , 0.3372549 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.6666667 , 1.        , 1.        , 0.6666667 ,\n",
       "       0.3372549 , 0.3372549 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.5529412 , 0.8862745 ,\n",
       "       0.6666667 , 0.22352941, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.3372549 , 1.        , 0.7764706 , 0.11372549, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.7764706 , 1.        ,\n",
       "       0.5529412 , 0.3372549 , 0.22352941, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.6666667 , 1.        , 0.7764706 , 0.44705883, 0.8862745 ,\n",
       "       0.6666667 , 0.11372549, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.22352941, 0.7764706 , 1.        , 0.44705883,\n",
       "       0.11372549, 0.        , 0.5529412 , 1.        , 0.11372549,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.44705883,\n",
       "       1.        , 0.44705883, 0.        , 0.        , 0.        ,\n",
       "       0.5529412 , 1.        , 0.11372549, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.11372549, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.8862745 , 1.        ,\n",
       "       0.11372549, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.44705883, 1.        , 0.5529412 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.3372549 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.44705883, 0.8862745 , 0.8862745 ,\n",
       "       0.11372549, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 1.        , 0.7764706 , 0.3372549 ,\n",
       "       0.        , 0.        , 0.        , 0.5529412 , 1.        ,\n",
       "       1.        , 0.6666667 , 0.11372549, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.8862745 , 1.        , 0.8862745 , 0.6666667 , 0.8862745 ,\n",
       "       1.        , 1.        , 0.7764706 , 0.11372549, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.3372549 , 0.7764706 ,\n",
       "       1.        , 1.        , 0.6666667 , 0.5529412 , 0.22352941,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize data from 0-255 to 0-1\n",
    "(x_train_original, y_train_original), (x_test_original, y_test_original) = mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = (x_train_original, y_train_original), (x_test_original, y_test_original)\n",
    "image_size = 28*28\n",
    "x_train = x_train.reshape(x_train.shape[0],image_size) # x_train = (60000,784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0],image_size)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "\n",
    "x_train[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical # to get a one-hot incoding of the target data\n",
    "num_classes = 10\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "y_test[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# test out the to_categorical method\n",
    "print(to_categorical([0],10))\n",
    "print(to_categorical([1],10))\n",
    "print(to_categorical([2],10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing layers for the model\n",
    "From Deep learning with python p. 59:\n",
    "\n",
    "Different layers are appropriate for different tensor formats and different types of data processing. For instance: \n",
    "1. simple vector data, stored in 2D tensors of shape (samples, features), is often processed by densely connected layers, also called fully connected or dense layers (the Dense class in Keras). \n",
    "2. Sequence data, stored in 3D tensors of shape (samples, timesteps, features), is typically processed by recurrent layers such as an LSTM layer.\n",
    "3. Image data, stored in 4D tensors, is usually processed by 2D convolution layers (Conv2D).\n",
    "\n",
    "Think of layers as the LEGO bricks of deep learning, a metaphor that is made explicit by frameworks like Keras. Building deep-learning models in Keras is done by clipping together compatible layers to form useful data-transformation pipelines. The notion of layer compatibility here refers specifically to the fact that every layer\n",
    "will only accept input tensors of a certain shape and will return output tensors of a certain shape. Consider the following example from keras import layers: `layer = layers.Dense(32, input_shape=(784,))`  \n",
    "A dense layer with 32 output units\n",
    "We’re creating a layer that will only accept as input 2D tensors where the first dimen-\n",
    "sion is 784 (axis 0, the batch dimension, is unspecified, and thus any value would be\n",
    "accepted). This layer will return a tensor where the first dimension has been trans-\n",
    "formed to be 32.\n",
    "\n",
    "Thus this layer can only be connected to a downstream layer that expects 32-\n",
    "dimensional vectors as its input. When using Keras, you don’t have to worry about\n",
    "compatibility, because the layers you add to your models are dynamically built to\n",
    "match the shape of the incoming layer. For instance, suppose you write the following:\n",
    "from keras import models\n",
    "from keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, input_shape=(784,)))\n",
    "model.add(layers.Dense(32))\n",
    "The second layer didn’t receive an input shape argument—instead, it automatically\n",
    "inferred its input shape as being the output shape of the layer that came before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "# model instance\n",
    "model = Sequential()\n",
    "# define each layer in the network\n",
    "from keras.layers import Dense # the simplest layer type\n",
    "\n",
    "input_layer = Dense(units=512,  # 512 units (nodes) is an arbitrary number (might be ajusted later up or down to see what gives most accuracy)\n",
    "                activation='sigmoid', # activation is the activation function used to pass dot product of all inputs and weights through\n",
    "                input_shape=(image_size, )) #28x28 for the mnist image size (must be an iterable, therefore the comma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in (image_size,):\n",
    "    print(i)\n",
    "print(len((image_size,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# add hidden layer\n",
    "model.add(input_layer)\n",
    "# add another  hidden layer\n",
    "model.add(Dense(units=512,activation='sigmoid'))\n",
    "\n",
    "#model.add(Dense(units=48,activation='relu'))\n",
    "\n",
    "# add an output layer\n",
    "model.add(Dense(units=10, \n",
    "                activation='softmax', # softmax nonlinearity function for mapping the neural network activation to the categories\n",
    "                #input_shape=(image_size,) # does not seem to be warranted\n",
    "               ))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 2.1417 - accuracy: 0.3331 - val_loss: 1.8759 - val_accuracy: 0.5585\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 1.4829 - accuracy: 0.6691 - val_loss: 1.0549 - val_accuracy: 0.8115\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.8880 - accuracy: 0.7931 - val_loss: 0.6649 - val_accuracy: 0.8623\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.6449 - accuracy: 0.8375 - val_loss: 0.5005 - val_accuracy: 0.8797\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.5326 - accuracy: 0.8588 - val_loss: 0.4211 - val_accuracy: 0.8955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe3d71e97d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now train the model\n",
    "model.compile(loss='categorical_crossentropy', # loss is how to meassure how wrong the model is on its predictions\n",
    "             optimizer='sgd', # \"stochastic gradient descent\" is a way to tell algorithm how to improve\n",
    "             metrics=['accuracy'], # what do we care about in our model\n",
    "             )\n",
    "model.fit(x_train,\n",
    "         y_train,\n",
    "         epochs=5,\n",
    "         verbose=True,\n",
    "         validation_split=0.1) # checking periodically how well we are doing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "- **Loss functions:** Different ways to calculate the difference between target and network output\n",
    "- **Optimizers:** Multiple variants of Stocastic Gradient Descent (SGD) that differ by taking into account previous weight updates when computing the next weight update, rather than just looking at the current value of the gradients. There is, for instance, SGD with momentum, as well as Adagrad, RMSProp, and several others. Such variants are known as optimization methods or optimizers.\n",
    "- **metrics:** What we are looking for when we optimize and readjust our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_original[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe3c44f0f10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, (ax1, ax2, ax3) = plt.subplots(1,3)\n",
    "ax1.imshow(x_test_original[0], cmap='Greys')\n",
    "ax2.imshow(x_test_original[1], cmap='Greys')\n",
    "ax3.imshow(x_test_original[2], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.8755\n",
      "test loss, test acc: [0.47166016697883606, 0.8755000233650208]\n",
      "\n",
      "# Generate predictions for 3 samples\n",
      "WARNING:tensorflow:From <ipython-input-16-9938d40614c9>:10: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "predict classes [7 2 1]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "print(f'test loss, test acc:', results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print('\\n# Generate predictions for 3 samples')\n",
    "predictions = model.predict(x_test[:3])\n",
    "#print('predictions shape:', predictions.shape)\n",
    "#print(predictions)\n",
    "print('predict classes',model.predict_classes(x_test[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "y_train first value [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "(60000, 10, 10)\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "num_classes = 10\n",
    "print(y_train.shape)\n",
    "print('y_train first value',y_train[0])\n",
    "# change the targets to one-hot-encoded\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "print(y_train.shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation here\n",
    "https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using convolutional neural network for image classification with keras\n",
    "https://www.machinecurve.com/index.php/2020/03/30/how-to-use-conv2d-with-keras/#what-are-convolutional-neural-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### more complex and more accurate model:\n",
    "\n",
    "\n",
    "# reformat input\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0],28,28,1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0],28,28,1)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "\n",
    "#reformat output\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "model2 = models.Sequential()\n",
    "# keras.layers.Conv2D(filters, kernel_size... filter is how many filters (windows of sub pixel set) kernel is the window size eg: 3x3 pixels\n",
    "model2.add(layers.Conv2D(32, (3,3), activation='relu',input_shape=(28,28,1)))\n",
    "model2.add(layers.MaxPool2D((2,2))) # Max Pooling to reduce the spatial dimensions of the output volume. pool_size: integer or tuple of 2 integers, factors by which to downscale (vertical, horizontal)\n",
    "model2.add(layers.Conv2D(64,(3,3),activation='relu')) # does not need input_shape, since it gets it from previous layer\n",
    "model2.add(layers.MaxPool2D((2,2)))\n",
    "model2.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model2.add(layers.Flatten()) # rewrite tensor to single vector of values\n",
    "model2.add(layers.Dense(64, activation='relu'))\n",
    "model2.add(layers.Dense(10, activation='softmax')) # softmax is good for output layer because Softmax outputs probabilities range. The range will 0 to 1, and the sum of all the probabilities will be equal to one. If the softmax function used for multi-classification model it returns the probabilities of each class and the target class will have the high probability.\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "844/844 [==============================] - 17s 21ms/step - loss: 0.1861 - accuracy: 0.9421 - val_loss: 0.0563 - val_accuracy: 0.9837\n",
      "Epoch 2/5\n",
      "844/844 [==============================] - 19s 22ms/step - loss: 0.0506 - accuracy: 0.9838 - val_loss: 0.0432 - val_accuracy: 0.9873\n",
      "Epoch 3/5\n",
      "844/844 [==============================] - 18s 21ms/step - loss: 0.0340 - accuracy: 0.9892 - val_loss: 0.0332 - val_accuracy: 0.9900\n",
      "Epoch 4/5\n",
      "844/844 [==============================] - 18s 22ms/step - loss: 0.0257 - accuracy: 0.9916 - val_loss: 0.0346 - val_accuracy: 0.9902\n",
      "Epoch 5/5\n",
      "844/844 [==============================] - 18s 22ms/step - loss: 0.0201 - accuracy: 0.9935 - val_loss: 0.0428 - val_accuracy: 0.9903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe3da114050>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy', # loss is how to meassure how wrong the model is on its predictions\n",
    "             optimizer='rmsprop', # \"stochastic gradient descent\" is a way to tell algorithm how to improve\n",
    "             metrics=['accuracy'], # what do we care about in our model\n",
    "             )\n",
    "model2.fit(x_train,\n",
    "         y_train,\n",
    "         epochs=5,\n",
    "         verbose=True,\n",
    "         batch_size=64,\n",
    "         validation_split=0.1) # checking periodically how well we are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0328 - accuracy: 0.9898\n",
      "test loss, test acc: [0.03275664895772934, 0.989799976348877]\n",
      "\n",
      "# Generate predictions for 3 samples\n",
      "[[1.11108005e-10 4.40638592e-09 1.29602560e-08 1.29090779e-06\n",
      "  3.69235892e-11 3.84837023e-10 5.82970141e-13 9.99998569e-01\n",
      "  1.92453387e-09 1.71947605e-07]\n",
      " [2.66724580e-08 8.69351879e-09 1.00000000e+00 3.20984211e-11\n",
      "  5.82322524e-11 3.48483500e-15 5.54748025e-09 2.43735641e-13\n",
      "  2.86523565e-11 4.14181710e-12]\n",
      " [1.78395453e-07 9.99996781e-01 2.01180477e-08 2.04812167e-08\n",
      "  9.06823516e-07 8.00246767e-07 1.26077964e-07 9.86727287e-07\n",
      "  1.98000365e-07 8.21571646e-08]]\n",
      "predict classes [7 2 1]\n",
      "actual:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "results = model2.evaluate(x_test, y_test)\n",
    "print('test loss, test acc:', results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print('\\n# Generate predictions for 3 samples')\n",
    "predictions = model2.predict(x_test[:3])\n",
    "#print('predictions shape:', predictions.shape)\n",
    "print(predictions)\n",
    "print('predict classes',model2.predict_classes(x_test[:3]))\n",
    "print('actual:\\n',y_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
