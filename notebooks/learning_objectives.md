# Learning objectives for each week of the python data science course

## Week 1

1. Python data types
2. Basic operators
3. String methods
4. Lists (indexing, slicing, copying, comprehensions)
5. Dicts (setDefault, nested dicts, comprehensions)
6. Sets (When to use them)
7. Tuples (When to use them)
8. Sorting
9. Multiple for-loops in list comprehensions.
10. Control structures: Loops
11. Control structures: Conditional Statements.
12. control structures: [Switch statements](https://www.freecodecamp.org/news/python-switch-statement-switch-case-example/)
13. Solution to week 1 exercises Part 1.
14. Solution to week 1 exercises Part 2.

## Week 2

1. Functions: Positional arguments, keyword arguments, default arguments, variable number of arguments.
2. Functions: Lambda functions
3. Functions: Recursion and Closures
4. Functions: [Decorators](https://www.programiz.com/python-programming/decorator)
5. Modules: Importing modules, aliases, relative imports, import function, `__name__`, `__main__` 
6. Modules: Packages, subpackages.
7. Import from sibling directories
8. Call module from command line with `python -m` and using arguments (optional and mandatory).
9. Read and write files
10. Json files
11. CSV files
12. openpyxl for excel files.
13. Zip and unzip files.
14. Test using `pytest`.
15. Type declarations using [`typing` module](https://docs.python.org/3/library/typing.html). 
16. DateTimes in python (time series data, convert from string, time delta)
17. Solution to week 2 exercises Part 1
18. Solution to week 2 exercises Part 2

## Week 3

1. OOP vs functional programming - Pros and cons.
2. Classes: Creating classes, instance variables, class variables, methods, constructors, access modifiers vs direct access.
3. @Property decorator
4. [Inheritance vs composition](https://realpython.com/inheritance-composition-python/) - Pros and cons.
5. Enums
6. [Solution to TextContainer problem using OOP](03-1&#32;Object-oriented&#32;Programming.ipynb#ex).
7. [Abstraction](https://www.javatpoint.com/abstraction-in-python).
8. Exceptions: try, except, else, finally.
9. Exceptions: Custom exceptions, raise, assert.
10. Solution to [Exception problem](03-2&#32;Exceptions.ipynb#ex).
11. Plotting with matplotlib: Setting the line style, color, marker, axis labels, legends, title, grid, subplots, saving figures.
12. Plotting with matplotlib: Histograms, scatter plots, bar charts, 
13. Plotting with matplotlib: pie charts, box plots, violin plots, heatmaps, contour plots or 3D plots.
14. Solution to [plotting exercise](03-3&#32;Plotting.ipynb#ex).
15. Solution to week 2 exercises Part 1.
16. Solution to week 2 exercises Part 2.

## Week 4

1. Understand the basics of NumPy arrays and their structure
2. Know how to create arrays and perform basic operations on them
3. Be able to perform element-wise operations on arrays
4. Understand broadcasting in NumPy (e.g., how to perform operations on arrays of different sizes)
5. Know how to index, slice and manipulate arrays
6. Know how to perform mathematical operations on arrays 
8. Know how to perform [statistical operations](https://data-flair.training/blogs/numpy-statistical-functions/) on arrays
9. Understand how to perform element-wise comparisons and [Boolean operations](http://www.math.buffalo.edu/~badzioch/MTH337/PT/PT-boolean_numpy_arrays/PT-boolean_numpy_arrays.html) on arrays
10. Know how to [generate random](https://www.w3schools.com/python/numpy/numpy_random.asp) numbers using NumPy
11. Know how to load and save arrays from/to files
12. Know how to merge and split arrays
1. Know how to sort arrays
1. Know how to perform operations along specific axes of arrays
1. Know how to use NumPy functions for [element-wise operations and aggregation](https://www.tutorialgateway.org/python-numpy-aggregate-functions/)
1. Know how to use NumPy functions for [set operations (e.g., union, intersection, etc.)](https://www.w3schools.com/python/numpy/numpy_ufunc_set_operations.asp)
1. Know how to extract and manipulate data from arrays (e.g., find unique elements, etc.)
1. Understand the difference between NumPy arrays and other Python data structures (e.g., lists)
1. Know how to use NumPy efficiently, including vectorized operations and memory management.
1. Know how to perform [reshaping and transposing](https://machinelearningknowledge.ai/numpy-shape-numpy-reshape-and-numpy-transpose-in-python/) operations on arrays

## Week 5

1. Understanding the Pandas DataFrame structure and how to create, manipulate, and index data within it.
2. Reading and writing data from different file formats, such as CSV, Excel, and SQL databases.
3. Selecting and filtering data using conditional statements and boolean indexing.
4. Grouping and aggregating data using functions such as groupby, pivot_table, and crosstab.
5. Handling missing data and dealing with duplicates.
6. Cleaning and transforming data using functions such as drop, fillna, and apply.
7. Merging and joining data from different DataFrames.
8. Working with time series data and date/time operations.
9. Reshaping and pivoting data.
10. Sorting data based on multiple columns or conditions.
11. Plotting data using the matplotlib and seaborn libraries.
12. Analyzing and summarizing data using descriptive statistics and other aggregating functions.
13. Performing basic statistical analysis on data.
14. Implementing custom functions to apply to Pandas data structures.

## Week 6

#### Webscraping

1. Understanding the basics of HTML structure and how to parse and extract information from it.
2. Installing and using the Beautiful Soup library to extract data from web pages.
3. Navigating and searching the HTML tree using tag names, attributes, and CSS selectors.
4. Extracting text and attribute values from HTML elements.
5. Iterating over multiple elements and extracting information from multiple pages.
6. Handling common errors and exceptions encountered during web scraping, such as 404 errors and connection issues.
7. Extracting data from tables and lists within web pages.
8. Integrating Beautiful Soup with other libraries such as requests and pandas for more advanced web scraping tasks.

#### Regular expressions

1. Understanding the basics of regular expressions, including metacharacters, character sets, and special syntax.
2. Using the re module in Python to search and match patterns in strings.
3. Extracting information from strings using the findall, search, and sub functions.
4. Specifying patterns using character sets, quantifiers, and grouping.
5. Replacing substrings in strings using regular expressions.
6. Matching specific characters or character classes using special syntax such as \d, \w, and \s.
7. Splitting strings into smaller components based on a pattern.
8. Understanding the use of greedy and non-greedy matching in regular expressions.
9. Validating strings using regular expressions, such as email addresses, phone numbers, and URLs.
10. Enhancing regular expression patterns using lookahead and lookbehind assertions, as well as conditional patterns.

### Selenium

1. Understanding the basics of Selenium and how to set it up in a Python environment.
1. Creating and running simple scripts to automate browser actions.
1. Locating elements on a web page using various methods, such as ID, class, and CSS selectors.
1. Interacting with elements on a web page, such as clicking buttons, filling out forms, and scrolling.
1. Navigating between pages and tabs within a browser.
1. Debugging and troubleshooting Selenium scripts to identify and fix issues.
1. Integrating Selenium with other tools and libraries, such as `beautifulsoup` and `re`, for more advanced web scraping and testing tasks.

## Project week 

- Semester Project part 1

## Week 8
### Feature spaces
1. Define what a feature space is and why it is important in data science.
2. Show how to represent data in a feature space.
3. Identify different types of feature spaces, including numerical, categorical, and text-based.
4. Show how to normalize data in a feature space.
5. Show how to deal with missing data in a feature space.
6. Show how to perform feature engineering to create new features.
7. Understand the concept of feature scaling and its importance in machine learning.
8. Explain the difference between linear and non-linear feature spaces.
9. Understand the concept of dimensionality reduction and how it can be used to simplify feature spaces.
10. Show how to use feature weighting techniques to assign different weights to features based on their importance.

### Linear algebra
1. Define what linear algebra is and why it is important in mathematics and data science.
2. Explain the difference between vectors and scalars, and how they can be used to represent data in linear algebra.
3. Explain the concept of matrix multiplication and how it can be used to combine matrices and perform transformations.
4. Understand how to use linear algebra to solve optimization problems, such as finding the minimum or maximum of a function.
5. Understand the concept of linear independence and linear dependence, and how they can be used to study vector spaces and solve systems of equations.

### Linear regression
1. Define what linear regression is and how it is used to model the relationship between a dependent variable and one or more independent variables.
2. Understand the assumptions of linear regression, such as linearity, independence and normality.
3. Explain the difference between simple linear regression and multiple linear regression, and when each is appropriate to use.
4. Explain how to handle categorical variables in linear regression using dummy variables or other encoding schemes.
5.  Explain how to handle outliers and influential points in linear regression using robust regression or other methods.

## Week 9
### Feature engineering
1. Define what feature engineering is and why it is important in data science.
2. Understand the difference between feature selection and feature extraction, and when each is appropriate to use.
3. Demonstrate the concept of feature weighting and how it can be used to assign different weights to features based on their importance.
4. Explain the concept of feature hashing and how it can be used to reduce the dimensionality of a feature space.
5. Demonstrate the concept of feature scaling and how it can be used to normalize data in a feature space.
6. Explain the concept of dimensionality reduction and how it can be used to simplify feature spaces.
7. Explain the concept of feature selection and how it can be used to reduce the dimensionality of a feature space.
8. Demonstrate the concept of feature extraction and how it can be used to create new features from existing ones.


### Clustering
1. Define what clustering is and why it is important in data science.
2. Understand the difference between supervised and unsupervised learning, and how clustering is an example of unsupervised learning.
3. Explain the concept of distance metrics (Euclidean and Manhattan) and how they can be used to measure the similarity or dissimilarity between data points.
4. Explain the concept of k-means clustering and how it works to find clusters of data points.
5. Understand how to choose the optimal number of clusters in k-means clustering using techniques such as the elbow method or silhouette score.
6. Demonstrate how to use k-means clustering to cluster data points into groups.
7. Demonstrate how to use mean shift clustering to cluster data points into groups.
8. Demonstrate real world applications of clustering, such as customer segmentation and anomaly detection.

6. Explain how to handle categorical variables in clustering [like this article describes](https://towardsdatascience.com/clustering-on-numerical-and-categorical-features-6e0ebcf1cbad) 
7. Demo how to make categorical variables numerical in clustering using one-hot encoding or other methods.
8. Understand how to use density-based clustering techniques, such as DBSCAN and OPTICS, to identify clusters of arbitrary shape and size.
9. Demonstrate how to make dummy data to test out clustering algorithms.
10. Explain the concept of cluster validity and how it can be used to evaluate the quality of the clusters.
11. Understand how to use dimensionality reduction techniques, such as principal component analysis (PCA), to reduce the dimensionality of the data before clustering.
12. Understand how to use clustering in anomaly detection to identify outliers and unusual patterns in the data.

## Week 10
### Neural Networks

1. Define what a neural network is and how it is used to model complex relationships between data.
2. Explain the difference between supervised and unsupervised learning, and how neural networks are an example of supervised learning.
3. Explain the concept of artificial neurons and how they can be used to model the human brain.
4. Demonstrate the concept of activation functions and how they can be used to introduce non-linearity into neural networks.
5. Explain the concept of backpropagation and how it can be used to train neural networks.
6. Explain the concept of gradient descent and how it can be used to train neural networks.
7. Explain the concept of regularization and how it can be used to prevent overfitting in neural networks.
8. Demonstrate the concept of deep learning and how it can be used to train neural networks with many layers.
9. Demonstrate the concept of transfer learning and how it can be used to train neural networks on new data using pre-trained models.
10. Demonstrate different types of neural network layers, such as dense, convolutional, and recurrent layers.

### Classification of images
1. Define what image classification is and how it is used to classify images into different categories.
2. Explain the difference between supervised and unsupervised learning, and how image classification is an example of supervised learning.
3. Explain the concept of convolutional neural networks and how they can be used to train neural networks on image data.
4. Demonstrate how to use convolutional neural networks to classify images into different categories.
5. Demonstrate how to use transfer learning to train convolutional neural networks on new data using pre-trained models.
6. Demonstrate different techniques for improving the performance of convolutional neural networks, such as data augmentation and dropout.
7. Demonstrate use of different types of convolutional neural networks, such as AlexNet, VGG, ResNet, and Inception.
8. Demonstrate use of different types of image classification datasets, such as ImageNet and CIFAR-10.
9. Demonstrate use of different activation functions in convolutional neural networks, such as ReLU, sigmoid, and softmax.
10. Demonstrate use of different types of pooling layers in convolutional neural networks, such as max pooling and average pooling.

## Week 11
### Working with images OpenCV
1. Understand the basics of image processing, including image representation and manipulation.
2. Learn how to load, display, and save images using OpenCV.
3. Master various image filtering techniques, such as smoothing, sharpening, and edge detection.
4. Implement morphological image processing techniques such as dilation, erosion, and opening/closing.
5. Use OpenCV to perform object detection and recognition.
6. Learn how to perform image segmentation using OpenCV.
7. Implement different image thresholding techniques to separate image regions based on intensity or color.
8. Understand the basics of image transformation, including scaling, rotation, and perspective transformations.
9. Use OpenCV to perform basic image restoration and noise reduction.
10. Learn how to use OpenCV with popular deep learning frameworks such as TensorFlow and PyTorch.
11. Apply image processing techniques to real-world applications such as medical imaging, surveillance, and robotics.

## Week 12
### Working with text
1. Understand the basics of NLP, including text preprocessing, tokenization, and normalization.
2. Learn how to extract key features from text data, such as n-grams, bag of words, and TF-IDF.
3. Learn how to use NLP libraries such as NLTK and spaCy for text processing and analysis.
4. Understand the principles behind named entity recognition and relation extraction.
5. Implement different techniques for text clustering and topic modeling.
6. Learn how to use deep learning-based architectures, such as Recurrent Neural Networks (RNNs) and Transformers, for text processing and analysis.
7. Understand the principles of sentiment analysis and emotion detection.
8. Learn how to use pre-trained language models, such as BERT and GPT, for various NLP tasks.
9. Learn how to use NLP for information retrieval and search engine optimization.
10. Apply NLP techniques to real-world applications such as chatbots, sentiment analysis in social media, and machine translation.